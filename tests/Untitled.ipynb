{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('scripts')))\n",
    "\n",
    "from extract_dataframe import read_json\n",
    "from extract_dataframe import TweetDfExtractor\n",
    "\n",
    "# For unit testing the data reading and processing codes, \n",
    "# we will need about 5 tweet samples. \n",
    "# Create a sample not more than 10 tweets and place it in a json file.\n",
    "# Provide the path to the samples tweets file you created below\n",
    "#sampletweetsjsonfile = \"./sampletweets.json\"   #put here the path to where you placed the file e.g. ./sampletweets.json. \n",
    "_, tweet_list = read_json(\"../sampletweets.json\" )\n",
    "\n",
    "columns = [\n",
    "    \"created_at\",\n",
    "    \"source\",\n",
    "    \"original_text\",\n",
    "    \"clean_text\",\n",
    "    \"sentiment\",\n",
    "    \"polarity\",\n",
    "    \"subjectivity\",\n",
    "    \"lang\",\n",
    "    \"favorite_count\",\n",
    "    \"retweet_count\",\n",
    "    \"original_author\",\n",
    "    \"screen_count\",\n",
    "    \"followers_count\",\n",
    "    \"friends_count\",\n",
    "    \"possibly_sensitive\",\n",
    "    \"hashtags\",\n",
    "    \"user_mentions\",\n",
    "    \"place\",\n",
    "    \"place_coord_boundaries\",\n",
    "]\n",
    "\n",
    "\n",
    "class TestTweetDfExtractor(unittest.TestCase):\n",
    "    \"\"\"\n",
    "\t\tA class for unit-testing function in the fix_clean_tweets_dataframe.py file\n",
    "\n",
    "\t\tArgs:\n",
    "        -----\n",
    "\t\t\tunittest.TestCase this allows the new class to inherit\n",
    "\t\t\tfrom the unittest module\n",
    "\t\"\"\"\n",
    "\n",
    "    def setUp(self) -> pd.DataFrame:\n",
    "        self.df = TweetDfExtractor(tweet_list[:5])\n",
    "        # tweet_df = self.df.get_tweet_df()\n",
    "\n",
    "    def test_find_statuses_count(self):\n",
    "        self.assertEqual(\n",
    "            self.df.find_statuses_count(), [8097,5831,1627,1627,18958]\n",
    "        )\n",
    "\n",
    "    def test_find_full_text(self):\n",
    "        text = [\"\"\"RT @i_ameztoy: Extra random image (I):\\n\\nLets focus in one very specific zone of the western coast -&gt; Longjing District, Taichung #City, #Ta\\u2026\"\"\",\n",
    "        \"\"\"Extra random image (I):\\n\\nLets focus in one very specific zone of the western coast -&gt; Longjing District, Taichung #City, #Taiwan \\n \\n#Copernicus #Sentinel2 \\ud83d\\udef0\\ufe0f 2022-08-03 \\nFull Size -&gt; https://t.co/39IOoqJZR9 \\ud83e\\uddd0 https://t.co/rdf21paD5P\"\"\",\n",
    "        \"\"\"RT @IndoPac_Info: #China's media explains the military reasons for each area of the drills in the #Taiwan Strait\\n\\nRead the labels in the pi\\u2026\"\"\",\n",
    "        \"\"\"#China's media explains the military reasons for each area of the drills in the #Taiwan Strait\\n\\nRead the labels in the pictures \\u2b07\\ufe0f Via CGTN https://t.co/0J4ilou4iv\"\"\",\n",
    "        \"\"\"China even cut off communication, they don't anwer phonecalls from the US. But here clown @ZelenskyyUa enters the stage to ask #XiJinping to change Putin's mind.\"\"\"]\n",
    "\n",
    "        self.assertEqual(self.df.find_full_text(), text)\n",
    "\n",
    "    \"\"\"\n",
    "    def test_find_sentiments(self):\n",
    "        self.assertEqual(\n",
    "            self.df.find_sentiments(self.df.find_full_text()),\n",
    "            (\\\n",
    "                [],\n",
    "                [],\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    \"\"\"\n",
    "    def test_find_screen_name(self):\n",
    "        name = ['i_ameztoy','IndoPac_Info','ZIisq','ZelenskyyUa','Fin21Free']\n",
    "        self.assertEqual(self.df.find_screen_name(), name)\n",
    "\n",
    "    def test_find_followers_count(self):\n",
    "        f_count = [20497,65,85,85,207]\n",
    "        self.assertEqual(self.df.find_followers_count(), f_count)\n",
    "\n",
    "    def test_find_friends_count(self):\n",
    "        friends_count = [2621,272,392,2608,54]\n",
    "        self.assertEqual(self.df.find_friends_count(), friends_count)\n",
    "\n",
    "    \"\"\" def test_find_is_sensitive(self):\n",
    "        self.assertEqual(self.df.is_sensitive(), [None,None,None,None,None])\n",
    "    \"\"\"\n",
    "\n",
    "    # def test_find_hashtags(self):\n",
    "    #     self.assertEqual(self.df.find_hashtags(), )\n",
    "\n",
    "    # def test_find_mentions(self):\n",
    "    #     self.assertEqual(self.df.find_mentions(), )\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement genism (from versions: none)\n",
      "ERROR: No matching distribution found for genism\n"
     ]
    }
   ],
   "source": [
    "pip install genism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f5c028248db3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def read_json(json_file: str)->list:\n",
    "    \"\"\"\n",
    "    json file reader to open and read json files into a list\n",
    "    Args:\n",
    "    -----\n",
    "    json_file: str - path of a json file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    length of the json file and a list of json\n",
    "    \"\"\"\n",
    "    \n",
    "    tweets_data = []\n",
    "    for tweets in open(\"data/global_twitter_data.json\",'r'):\n",
    "        tweets_data.append(json.loads(tweets))\n",
    "    \n",
    "    \n",
    "    return len(tweets_data), tweets_data\n",
    "\n",
    "class TweetDfExtractor:\n",
    "    \"\"\"\n",
    "    this function will parse tweets json into a pandas dataframe\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self, tweets_list):\n",
    "        \n",
    "        self.tweets_list = tweets_list\n",
    "        print('in progress...')\n",
    "    # an example function\n",
    "    def find_statuses_count(self) -> list:\n",
    "        statuses_count = []\n",
    "        for tweet in self.tweets_list:\n",
    "            statuses_count.append(tweet['user']['statuses_count'])\n",
    "        return statuses_count  \n",
    "\n",
    "    def find_retweet_text(self) -> list:\n",
    "        full_text = []\n",
    "        for tweet in self.tweets_list:\n",
    "            try:\n",
    "                full_text.append(\n",
    "                    tweet['retweeted_status']['text'])\n",
    "            except KeyError:\n",
    "                full_text.append(\"\")\n",
    "        return full_text\n",
    "\n",
    "    def find_original_text(self) -> list:\n",
    "        text = []\n",
    "        for tweet in self.tweets_list:\n",
    "            try:\n",
    "                text.append(tweet['retweeted_status']\n",
    "                            ['extended_tweet']['full_text'])\n",
    "            except KeyError:\n",
    "                text.append(tweet['full_text'])\n",
    "        return text\n",
    "\n",
    "    def find_sentiments(self, text: list) -> list:\n",
    "        polarity = []\n",
    "        subjectivity = []\n",
    "        for tweet in text:\n",
    "            blob = TextBlob(tweet)\n",
    "            sentiment = blob.sentiment\n",
    "            polarity.append(sentiment.polarity)\n",
    "            subjectivity.append(sentiment.subjectivity)\n",
    "        return polarity, subjectivity\n",
    "\n",
    "    def find_sentiment_polarity(self, polarity, subjectivity) -> list:\n",
    "        sentiment = []\n",
    "        for i in range(len(polarity)):\n",
    "            if polarity[i] > 0:\n",
    "                sentiment.append(1)\n",
    "            elif polarity[i] < 0:\n",
    "                sentiment.append(0)\n",
    "            else:\n",
    "                sentiment.append(-1)\n",
    "        return sentiment\n",
    "\n",
    "    def find_created_time(self) -> list:\n",
    "        created_at = []\n",
    "        for time in self.tweets_list:\n",
    "            created_at.append(time['created_at'])\n",
    "        return created_at\n",
    "\n",
    "    def find_source(self) -> list:\n",
    "        source = []\n",
    "        for x in self.tweets_list:\n",
    "            source.append(x['source'])\n",
    "        return source\n",
    "\n",
    "    def find_screen_name(self) -> list:\n",
    "        screen_name = []\n",
    "        for x in self.tweets_list:\n",
    "            screen_name.append(x['user']['screen_name'])\n",
    "        return screen_name\n",
    "\n",
    "    def find_followers_count(self) -> list:\n",
    "        followers_count = []\n",
    "\n",
    "        for x in self.tweets_list:\n",
    "            if 'retweeted_status' in x.keys():\n",
    "                followers_count.append(\n",
    "                    x['retweeted_status']['user']['followers_count'])\n",
    "            else:\n",
    "                followers_count.append(0)\n",
    "        return followers_count\n",
    "\n",
    "    def find_friends_count(self) -> list:\n",
    "        friends_count = []\n",
    "        for x in self.tweets_list:\n",
    "            friends_count.append(x['user']['friends_count'])\n",
    "        return friends_count\n",
    "\n",
    "    def is_sensitive(self) -> list:\n",
    "        is_sensitive = []\n",
    "        for tweet in self.tweets_list:\n",
    "            if 'possibly_sensitive' in tweet.keys():\n",
    "                is_sensitive.append(tweet['possibly_sensitive'])\n",
    "            else:\n",
    "                is_sensitive.append(None)\n",
    "        return is_sensitive\n",
    "\n",
    "    def find_favourite_count(self) -> list:\n",
    "        favorite_count = []\n",
    "        for tweet in self.tweets_list:\n",
    "            if 'retweeted_status' in tweet.keys():\n",
    "                favorite_count.append(\n",
    "                    tweet['retweeted_status']['favorite_count'])\n",
    "            else:\n",
    "                favorite_count.append(0)\n",
    "        return favorite_count\n",
    "\n",
    "    def find_retweet_count(self) -> list:\n",
    "        retweet_count = []\n",
    "        for tweet in self.tweets_list:\n",
    "            if 'retweeted_status' in tweet.keys():\n",
    "                retweet_count.append(\n",
    "                    tweet['retweeted_status']['retweet_count'])\n",
    "            else:\n",
    "                retweet_count.append(0)\n",
    "        return retweet_count\n",
    "\n",
    "    def find_hashtags(self) -> list:\n",
    "        hashtags = []\n",
    "        for tweet in self.tweets_list:\n",
    "            try:\n",
    "                hashtags.append(tweet['entities']['hashtags'][0]['text'])\n",
    "            except KeyError:\n",
    "                hashtags.append(None)\n",
    "            except IndexError:\n",
    "                hashtags.append(None)\n",
    "        return hashtags\n",
    "\n",
    "    def find_mentions(self) -> list:\n",
    "        mentions = []\n",
    "        for hs in self.tweets_list:\n",
    "            mentions.append(\", \".join(\n",
    "                [mention['screen_name'] for mention in hs['entities']['user_mentions']]))\n",
    "        return mentions\n",
    "\n",
    "    def find_lang(self) -> list:\n",
    "        lang = []\n",
    "        for x in self.tweets_list:\n",
    "            lang.append(x['lang'])\n",
    "        return lang\n",
    "\n",
    "    def find_location(self) -> list:\n",
    "        location = []\n",
    "        for tweet in self.tweets_list:\n",
    "            location.append(tweet['user']['location'])\n",
    "        return location\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    def get_tweet_df(self, save=False) -> pd.DataFrame:\n",
    "        \"\"\"required column to be generated you should be creative and add more features\"\"\"\n",
    "\n",
    "        columns = ['created_at', 'source', 'original_text','retweet_text','sentiment','polarity','subjectivity', 'lang', 'favorite_count', 'retweet_count', \n",
    "            'original_author', 'followers_count','friends_count','possibly_sensitive', 'hashtags', 'user_mentions', 'place']\n",
    "        \n",
    "        created_at = self.find_created_time()\n",
    "        source = self.find_source()\n",
    "        text = self.find_original_text()\n",
    "        retweet_text = self.find_retweet_text()\n",
    "        polarity, subjectivity = self.find_sentiments(text)\n",
    "        sentiment = self.find_sentiment_polarity(polarity, subjectivity)\n",
    "        lang = self.find_lang()\n",
    "        fav_count = self.find_favourite_count()\n",
    "        retweet_count = self.find_retweet_count()\n",
    "        screen_name = self.find_screen_name()\n",
    "        follower_count = self.find_followers_count()\n",
    "        friends_count = self.find_friends_count()\n",
    "        sensitivity = self.is_sensitive()\n",
    "        hashtags = self.find_hashtags()\n",
    "        mentions = self.find_mentions()\n",
    "        location = self.find_location()\n",
    "        data = zip(created_at, source, text,retweet_text, sentiment, polarity, subjectivity, lang, fav_count, retweet_count, screen_name, follower_count, friends_count, sensitivity, hashtags, mentions, location)\n",
    "        df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "        if save:\n",
    "            df.to_csv('data/processed_tweet_data.csv', index=False)\n",
    "            print('File Successfully Saved.!!!')\n",
    "        \n",
    "        return df\n",
    "\n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "    # required column to be generated you should be creative and add more features\n",
    "    _, tweet_list = read_json(\"data/global_twitter_data.json\")\n",
    "    tweet = TweetDfExtractor(tweet_list)\n",
    "    tweet_df = tweet.get_tweet_df(True) \n",
    "    #tweet.find_statuses_count() ##since statuses count is in the test\n",
    "\n",
    "    # use all defined functions to generate a dataframe with the specified columns above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1; python_version >= \"3\" in c:\\users\\amanuel\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\amanuel\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (4.47.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\amanuel\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (0.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\amanuel\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\amanuel\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (2020.6.8)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/global_twitter_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f5c028248db3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;31m# required column to be generated you should be creative and add more features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/global_twitter_data.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m     \u001b[0mtweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTweetDfExtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0mtweet_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tweet_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f5c028248db3>\u001b[0m in \u001b[0;36mread_json\u001b[1;34m(json_file)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtweets_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtweets\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/global_twitter_data.json\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mtweets_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/global_twitter_data.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def read_json(json_file: str)->list:\n",
    "    \"\"\"\n",
    "    json file reader to open and read json files into a list\n",
    "    Args:\n",
    "    -----\n",
    "    json_file: str - path of a json file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    length of the json file and a list of json\n",
    "    \"\"\"\n",
    "    \n",
    "    tweets_data = []\n",
    "    for tweets in open(\"data/global_twitter_data.json\",'r'):\n",
    "        tweets_data.append(json.loads(tweets))\n",
    "    \n",
    "    \n",
    "    return len(tweets_data), tweets_data\n",
    "\n",
    "class TweetDfExtractor:\n",
    "    \"\"\"\n",
    "    this function will parse tweets json into a pandas dataframe\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self, tweets_list):\n",
    "        \n",
    "        self.tweets_list = tweets_list\n",
    "        print('in progress...')\n",
    "    # an example function\n",
    "    def find_statuses_count(self) -> list:\n",
    "        statuses_count = []\n",
    "        for tweet in self.tweets_list:\n",
    "            statuses_count.append(tweet['user']['statuses_count'])\n",
    "        return statuses_count  \n",
    "\n",
    "    def find_retweet_text(self) -> list:\n",
    "        full_text = []\n",
    "        for tweet in self.tweets_list:\n",
    "            try:\n",
    "                full_text.append(\n",
    "                    tweet['retweeted_status']['text'])\n",
    "            except KeyError:\n",
    "                full_text.append(\"\")\n",
    "        return full_text\n",
    "\n",
    "    def find_original_text(self) -> list:\n",
    "        text = []\n",
    "        for tweet in self.tweets_list:\n",
    "            try:\n",
    "                text.append(tweet['retweeted_status']\n",
    "                            ['extended_tweet']['full_text'])\n",
    "            except KeyError:\n",
    "                text.append(tweet['full_text'])\n",
    "        return text\n",
    "\n",
    "    def find_sentiments(self, text: list) -> list:\n",
    "        polarity = []\n",
    "        subjectivity = []\n",
    "        for tweet in text:\n",
    "            blob = TextBlob(tweet)\n",
    "            sentiment = blob.sentiment\n",
    "            polarity.append(sentiment.polarity)\n",
    "            subjectivity.append(sentiment.subjectivity)\n",
    "        return polarity, subjectivity\n",
    "\n",
    "    def find_sentiment_polarity(self, polarity, subjectivity) -> list:\n",
    "        sentiment = []\n",
    "        for i in range(len(polarity)):\n",
    "            if polarity[i] > 0:\n",
    "                sentiment.append(1)\n",
    "            elif polarity[i] < 0:\n",
    "                sentiment.append(0)\n",
    "            else:\n",
    "                sentiment.append(-1)\n",
    "        return sentiment\n",
    "\n",
    "    def find_created_time(self) -> list:\n",
    "        created_at = []\n",
    "        for time in self.tweets_list:\n",
    "            created_at.append(time['created_at'])\n",
    "        return created_at\n",
    "\n",
    "    def find_source(self) -> list:\n",
    "        source = []\n",
    "        for x in self.tweets_list:\n",
    "            source.append(x['source'])\n",
    "        return source\n",
    "\n",
    "    def find_screen_name(self) -> list:\n",
    "        screen_name = []\n",
    "        for x in self.tweets_list:\n",
    "            screen_name.append(x['user']['screen_name'])\n",
    "        return screen_name\n",
    "\n",
    "    def find_followers_count(self) -> list:\n",
    "        followers_count = []\n",
    "\n",
    "        for x in self.tweets_list:\n",
    "            if 'retweeted_status' in x.keys():\n",
    "                followers_count.append(\n",
    "                    x['retweeted_status']['user']['followers_count'])\n",
    "            else:\n",
    "                followers_count.append(0)\n",
    "        return followers_count\n",
    "\n",
    "    def find_friends_count(self) -> list:\n",
    "        friends_count = []\n",
    "        for x in self.tweets_list:\n",
    "            friends_count.append(x['user']['friends_count'])\n",
    "        return friends_count\n",
    "\n",
    "    def is_sensitive(self) -> list:\n",
    "        is_sensitive = []\n",
    "        for tweet in self.tweets_list:\n",
    "            if 'possibly_sensitive' in tweet.keys():\n",
    "                is_sensitive.append(tweet['possibly_sensitive'])\n",
    "            else:\n",
    "                is_sensitive.append(None)\n",
    "        return is_sensitive\n",
    "\n",
    "    def find_favourite_count(self) -> list:\n",
    "        favorite_count = []\n",
    "        for tweet in self.tweets_list:\n",
    "            if 'retweeted_status' in tweet.keys():\n",
    "                favorite_count.append(\n",
    "                    tweet['retweeted_status']['favorite_count'])\n",
    "            else:\n",
    "                favorite_count.append(0)\n",
    "        return favorite_count\n",
    "\n",
    "    def find_retweet_count(self) -> list:\n",
    "        retweet_count = []\n",
    "        for tweet in self.tweets_list:\n",
    "            if 'retweeted_status' in tweet.keys():\n",
    "                retweet_count.append(\n",
    "                    tweet['retweeted_status']['retweet_count'])\n",
    "            else:\n",
    "                retweet_count.append(0)\n",
    "        return retweet_count\n",
    "\n",
    "    def find_hashtags(self) -> list:\n",
    "        hashtags = []\n",
    "        for tweet in self.tweets_list:\n",
    "            try:\n",
    "                hashtags.append(tweet['entities']['hashtags'][0]['text'])\n",
    "            except KeyError:\n",
    "                hashtags.append(None)\n",
    "            except IndexError:\n",
    "                hashtags.append(None)\n",
    "        return hashtags\n",
    "\n",
    "    def find_mentions(self) -> list:\n",
    "        mentions = []\n",
    "        for hs in self.tweets_list:\n",
    "            mentions.append(\", \".join(\n",
    "                [mention['screen_name'] for mention in hs['entities']['user_mentions']]))\n",
    "        return mentions\n",
    "\n",
    "    def find_lang(self) -> list:\n",
    "        lang = []\n",
    "        for x in self.tweets_list:\n",
    "            lang.append(x['lang'])\n",
    "        return lang\n",
    "\n",
    "    def find_location(self) -> list:\n",
    "        location = []\n",
    "        for tweet in self.tweets_list:\n",
    "            location.append(tweet['user']['location'])\n",
    "        return location\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    def get_tweet_df(self, save=False) -> pd.DataFrame:\n",
    "        \"\"\"required column to be generated you should be creative and add more features\"\"\"\n",
    "\n",
    "        columns = ['created_at', 'source', 'original_text','retweet_text','sentiment','polarity','subjectivity', 'lang', 'favorite_count', 'retweet_count', \n",
    "            'original_author', 'followers_count','friends_count','possibly_sensitive', 'hashtags', 'user_mentions', 'place']\n",
    "        \n",
    "        created_at = self.find_created_time()\n",
    "        source = self.find_source()\n",
    "        text = self.find_original_text()\n",
    "        retweet_text = self.find_retweet_text()\n",
    "        polarity, subjectivity = self.find_sentiments(text)\n",
    "        sentiment = self.find_sentiment_polarity(polarity, subjectivity)\n",
    "        lang = self.find_lang()\n",
    "        fav_count = self.find_favourite_count()\n",
    "        retweet_count = self.find_retweet_count()\n",
    "        screen_name = self.find_screen_name()\n",
    "        follower_count = self.find_followers_count()\n",
    "        friends_count = self.find_friends_count()\n",
    "        sensitivity = self.is_sensitive()\n",
    "        hashtags = self.find_hashtags()\n",
    "        mentions = self.find_mentions()\n",
    "        location = self.find_location()\n",
    "        data = zip(created_at, source, text,retweet_text, sentiment, polarity, subjectivity, lang, fav_count, retweet_count, screen_name, follower_count, friends_count, sensitivity, hashtags, mentions, location)\n",
    "        df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "        if save:\n",
    "            df.to_csv('data/processed_tweet_data.csv', index=False)\n",
    "            print('File Successfully Saved.!!!')\n",
    "        \n",
    "        return df\n",
    "\n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "    # required column to be generated you should be creative and add more features\n",
    "    _, tweet_list = read_json(\"data/global_twitter_data.json\")\n",
    "    tweet = TweetDfExtractor(tweet_list)\n",
    "    tweet_df = tweet.get_tweet_df(True) \n",
    "    #tweet.find_statuses_count() ##since statuses count is in the test\n",
    "\n",
    "    # use all defined functions to generate a dataframe with the specified columns above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
